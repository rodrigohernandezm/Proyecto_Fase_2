# ğŸ“Š Proyecto Fase 2 â€“ Modelos Predictivos (Ãrboles, Random Forest y Redes Neuronales)

Esta fase lleva el proyecto de faltas judiciales un paso adelante: a partir del dataset integrado/limpio (2018â€“2024) se construyen modelos **supervisados** para predecir variables clave como tipo de falta, grupo etario, nivel educativo, Ã¡rea geogrÃ¡fica y aÃ±o de la boleta. El flujo incluye:

- **R (`Fase_2.R`)**: Ã¡rboles de decisiÃ³n con `rpart` y ensambles **Random Forest** para distintos objetivos.
- **Python (`redes_neuronales.ipynb`)**: redes neuronales densas en TensorFlow/Keras para clasificaciÃ³n multiclase y binaria.

---

## ğŸ“ Estructura del proyecto

```
/Proyecto_Fase_2/
â”œâ”€â”€ Fase_2.R                   # Script principal en R (Ã¡rboles de decisiÃ³n y random forest)
â”œâ”€â”€ redes_neuronales.ipynb     # Notebook en Python/TensorFlow para redes densas
â”œâ”€â”€ datasets/                  # Archivos Excel consolidados por aÃ±o
â”‚   â”œâ”€â”€ faltas-judiciales-ano-2018.xlsx
â”‚   â”œâ”€â”€ faltas-judiciales-ano-2019.xlsx
â”‚   â”œâ”€â”€ faltas-judiciales-ano-2020.xlsx
â”‚   â”œâ”€â”€ faltas-judiciales-ano-2021.xlsx
â”‚   â”œâ”€â”€ faltas-judiciales-ano-2022.xlsx
â”‚   â”œâ”€â”€ faltas-judiciales-2023.xlsx
â”‚   â””â”€â”€ base-faltas-judiciales-2024.xlsx
â”œâ”€â”€ arbol_*.png                # GrÃ¡ficas exportadas de los Ã¡rboles de decisiÃ³n
â”œâ”€â”€ random_forest_*.png        # GrÃ¡ficas e importancias de los bosques aleatorios
â””â”€â”€ red_neuronal_*.png         # Curvas y matrices de las redes neuronales
```

---

## âš™ï¸ Requisitos de ejecuciÃ³n

### Datos
Coloque todos los Excel anuales dentro de `datasets/`. El cÃ³digo identifica el aÃ±o a partir del nombre del archivo (`...2019.xlsx`, `...2024.xlsx`, etc.).

### Sistema operativo
Probado en **Windows, macOS y Linux**. Ajuste las rutas segÃºn su entorno.

### R (Fase_2.R)
- **VersiÃ³n recomendada:** R â‰¥ 4.2.
- **IDE:** RStudio (sugerido) o terminal con `Rscript`.
- **Paquetes necesarios:**
  ```r
  install.packages(c(
    "readxl", "stringi", "dplyr", "arules", "rpart", "rpart.plot",
    "randomForest", "entropy"
  ))
  ```

### Python (notebook `redes_neuronales.ipynb`)
- **VersiÃ³n recomendada:** Python 3.10 o 3.11.
- **Entorno:** Jupyter Notebook o VS Code con soporte para notebooks.
- **Dependencias principales:**
  ```bash
  python -m venv .venv
  source .venv/bin/activate   # Windows: .venv\Scripts\activate
  pip install numpy pandas tensorflow scikit-learn seaborn unidecode
  ```

---

## ğŸ“¥ Clonar el repositorio

```bash
git clone https://github.com/rodrigohernandezm/Proyecto_Fase_2
cd Proyecto_Fase_2
```

---

## ğŸš€ EjecuciÃ³n en R: Ãrboles de decisiÃ³n y Random Forest

1. **Configurar la ruta de datos**  
   Abra `Fase_2.R` y ajuste `ruta <- ".../datasets"` para apuntar a su carpeta local (ejemplos: `"D:/Proyectos/Proyecto_Fase_2/datasets"` en Windows o `"/home/usuario/Proyecto_Fase_2/datasets"` en Linux/macOS).

2. **Carga e integraciÃ³n**  
   - Se leen todos los `.xlsx`, se extrae el aÃ±o del nombre y se crean data frames `df_2018`â€“`df_2024`.
   - Se estandarizan nombres de columnas (minÃºsculas, sin acentos) y se homologa nomenclatura (`gran_grupos`, `subg_principales`, etc.).
   - Se descartan columnas inconsistentes (`edad_quinquenales`, `ocupacionhabitual`, `filter_$`) y se convierte `area_geo_inf` a numÃ©rico.  
   - Se consolidan los aÃ±os 2020â€“2024 en `df_final`, eliminando `num_corre`.

3. **Ãrboles de decisiÃ³n (`rpart`)**  
   - **Tipo de falta (`a_1`)**: predice `falta_inf` usando variables sociodemogrÃ¡ficas y geogrÃ¡ficas. Incluye ejemplos de predicciÃ³n para perfiles sintÃ©ticos.  
   - **Grupo etario (`a_2`)**: clasifica en `edad_quinquenal` a partir de falta, aÃ±o, sexo, alfabetismo, Ã¡rea, etc.  
   - **Escolaridad y aÃ±o de boleta**: Ã¡rboles adicionales sobre `niv_escolaridad_inf` y `ano_boleta` (ver secciones posteriores del script).  
   - Cada Ã¡rbol se grafica con `rpart.plot` y puede exportarse (`arbol_1.png`, `arbol_2.png`, etc.).

4. **Random Forest (`randomForest`)**  
   - Modelos de ensamble para **tipo de falta**, **sexo** y **Ã¡rea geogrÃ¡fica (urbano/rural)**.  
   - ParÃ¡metros definidos en el script (p.ej., `ntree`, `mtry`) con `set.seed(42)` para reproducibilidad.  
   - Se generan mÃ©tricas de exactitud, matrices de confusiÃ³n e importancia de variables (exportadas a `random_forest_*.png`).

5. **EjecuciÃ³n completa**  
   - Desde RStudio: *Source* (`Ctrl + Shift + Enter`).  
   - Desde terminal: `Rscript Fase_2.R`.

6. **Salidas esperadas**  
   - MÃ©tricas impresas en consola (accuracy, matriz de confusiÃ³n).  
   - GrÃ¡ficos de Ã¡rboles y bosques en PNG.  
   - Predicciones de prueba para perfiles sintÃ©ticos (en consola).

---

## ğŸ¤– EjecuciÃ³n en Python: Redes Neuronales Densas

1. **Activar entorno**  
   - Inicie el entorno virtual y asegÃºrese de tener las dependencias instaladas (`pip install ...`).

2. **Abrir el notebook**  
   - `jupyter notebook redes_neuronales.ipynb` (o Ã¡bralo en VS Code).  
   - Ajuste la variable `ruta` en la primera celda para que apunte a su carpeta `datasets` local.

3. **Carga y preparaciÃ³n de datos**  
   - Se leen los mismos Excel usados en R, se unifican columnas y se codifican categorÃ­as (limpieza con `unidecode`, `LabelEncoder`, `to_categorical`).
   - Se separan conjuntos de entrenamiento/prueba con `train_test_split` y se escalan variables numÃ©ricas con `StandardScaler`.

4. **Arquitecturas de red**  
   - **Red 1 (aÃ±o de la falta)**: capas `Dense` con activaciÃ³n ReLU y salida softmax para predecir `ano_boleta`.  
   - **Red 2 (tipo de falta u objetivo indicado en el notebook)**: configuraciÃ³n similar, con funciÃ³n de pÃ©rdida y activaciÃ³n acordes a si es binario o multiclase.  
   - Uso de `EarlyStopping` y optimizador `Adam`.  
   - Clase balanceada opcional con `compute_class_weight` segÃºn la distribuciÃ³n de etiquetas.

5. **Entrenamiento y evaluaciÃ³n**  
   - Ejecute las celdas en orden. El notebook muestra el resumen del modelo, el proceso de entrenamiento y las mÃ©tricas (accuracy, matriz de confusiÃ³n).  
   - Las grÃ¡ficas de curvas y matrices pueden guardarse como `red_neuronal_*.png`.

6. **Resultados**  
   - MÃ©tricas y tablas impresas en el notebook.  
   - Visualizaciones de desempeÃ±o (pÃ©rdida/accuracy por Ã©poca, matriz de confusiÃ³n).  
   - Predicciones sobre perfiles sintÃ©ticos demostrativos.

---

## ğŸ§  ExplicaciÃ³n tÃ©cnica resumida

- **Ãrboles de decisiÃ³n (`rpart`)**: dividen el espacio de atributos maximizando la ganancia de informaciÃ³n (medida con entropÃ­a). Cada nodo evalÃºa variables como `sexo_inf`, `edad_inf`, `area_geo_inf`, `gran_grupos`, etc.; las hojas asignan la clase mayoritaria. Las grÃ¡ficas `arbol_*.png` facilitan interpretar reglas y nodos terminales.

- **Random Forest**: ensamble de mÃºltiples Ã¡rboles entrenados sobre subconjuntos de variables/filas. Se controlan parÃ¡metros como nÃºmero de Ã¡rboles (`ntree`) y nÃºmero de variables por split (`mtry`). La importancia de variables se reporta en los grÃ¡ficos `random_forest_*.png`, Ãºtil para comparar quÃ© atributos aportan mÃ¡s a la predicciÃ³n de falta, sexo o Ã¡rea.

- **Redes neuronales densas (Keras)**: modelos `Sequential` con capas `Dense` y activaciones ReLU; la capa de salida usa softmax (multiclase) o sigmoid (binario). Se normalizan entradas y se aplican callbacks de parada temprana. Las mÃ©tricas principales son accuracy y matriz de confusiÃ³n sobre el conjunto de prueba.

---

## ğŸ” Reproducibilidad y buenas prÃ¡cticas
- El script en R fija semillas (`set.seed(42)`) antes de entrenar Random Forest; puede ajustarlas para replicar exactamente los resultados.
- En Python, defina semillas manualmente (`np.random.seed(...)`, `tf.random.set_seed(...)`) si necesita ejecuciones deterministas.
- Revise que no existan valores faltantes inesperados tras la limpieza y que las columnas categÃ³ricas queden correctamente codificadas.
- Si ejecuta en entornos sin interfaz grÃ¡fica, configure la salida de plots a archivos PNG en lugar de mostrarlos en pantalla.

---

## ğŸ‘¤ Autor
**Rodrigo Eduardo HernÃ¡ndez Morales**  
MaestrÃ­a en Ciencia de la ComputaciÃ³n â€“ Especialidad en Ciencia de Datos  
Universidad de San Carlos de Guatemala
