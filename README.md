# üìä Proyecto Fase 2 ‚Äì Modelos Predictivos (√Årboles, Random Forest y Redes Neuronales)

Esta fase lleva el proyecto de faltas judiciales un paso adelante: a partir del dataset integrado/limpio (2018‚Äì2024) se construyen modelos **supervisados** para predecir variables clave como tipo de falta, grupo etario, nivel educativo, √°rea geogr√°fica y a√±o de la boleta. El flujo incluye:

- **R (`Fase_2.R`)**: √°rboles de decisi√≥n con `rpart` y ensambles **Random Forest** para distintos objetivos.
- **Python (`redes_neuronales.ipynb`)**: redes neuronales densas en TensorFlow/Keras para clasificaci√≥n multiclase y binaria.

Todo est√° documentado para que cualquier ingeniero pueda clonar el repositorio, instalar las dependencias y reproducir los resultados (m√©tricas, matrices de confusi√≥n y gr√°ficas exportadas).

---

## üìÅ Estructura del proyecto

```
/Proyecto_Fase_2/
‚îú‚îÄ‚îÄ Fase_2.R                   # Script principal en R (√°rboles de decisi√≥n y random forest)
‚îú‚îÄ‚îÄ redes_neuronales.ipynb     # Notebook en Python/TensorFlow para redes densas
‚îú‚îÄ‚îÄ datasets/                  # Archivos Excel consolidados por a√±o
‚îÇ   ‚îú‚îÄ‚îÄ faltas-judiciales-ano-2018.xlsx
‚îÇ   ‚îú‚îÄ‚îÄ faltas-judiciales-ano-2019.xlsx
‚îÇ   ‚îú‚îÄ‚îÄ faltas-judiciales-ano-2020.xlsx
‚îÇ   ‚îú‚îÄ‚îÄ faltas-judiciales-ano-2021.xlsx
‚îÇ   ‚îú‚îÄ‚îÄ faltas-judiciales-ano-2022.xlsx
‚îÇ   ‚îú‚îÄ‚îÄ faltas-judiciales-2023.xlsx
‚îÇ   ‚îî‚îÄ‚îÄ base-faltas-judiciales-2024.xlsx
‚îú‚îÄ‚îÄ arbol_*.png                # Gr√°ficas exportadas de los √°rboles de decisi√≥n
‚îú‚îÄ‚îÄ random_forest_*.png        # Gr√°ficas e importancias de los bosques aleatorios
‚îî‚îÄ‚îÄ red_neuronal_*.png         # Curvas y matrices de las redes neuronales
```

> ‚ÑπÔ∏è Los PNG presentes son ejemplos generados al correr los modelos. Puede regenerarlos ejecutando los scripts/notebooks con soporte gr√°fico.

---

## ‚öôÔ∏è Requisitos de ejecuci√≥n

### Datos
Coloque todos los Excel anuales dentro de `datasets/`. El c√≥digo identifica el a√±o a partir del nombre del archivo (`...2019.xlsx`, `...2024.xlsx`, etc.).

### Sistema operativo
Probado en **Windows, macOS y Linux**. Ajuste las rutas seg√∫n su entorno.

### R (Fase_2.R)
- **Versi√≥n recomendada:** R ‚â• 4.2.
- **IDE:** RStudio (sugerido) o terminal con `Rscript`.
- **Paquetes necesarios:**
  ```r
  install.packages(c(
    "readxl", "stringi", "dplyr", "arules", "rpart", "rpart.plot",
    "randomForest", "entropy"
  ))
  ```

### Python (notebook `redes_neuronales.ipynb`)
- **Versi√≥n recomendada:** Python 3.10 o 3.11.
- **Entorno:** Jupyter Notebook o VS Code con soporte para notebooks.
- **Dependencias principales:**
  ```bash
  python -m venv .venv
  source .venv/bin/activate   # Windows: .venv\Scripts\activate
  pip install numpy pandas tensorflow scikit-learn seaborn unidecode
  ```

---

## üì• Clonar el repositorio

```bash
git clone <URL_DEL_REPO_FASE_2>
cd Proyecto_Fase_2
```

Reemplace `<URL_DEL_REPO_FASE_2>` por la URL real (HTTPS o SSH).

---

## üöÄ Ejecuci√≥n en R: √Årboles de decisi√≥n y Random Forest

1. **Configurar la ruta de datos**  
   Abra `Fase_2.R` y ajuste `ruta <- ".../datasets"` para apuntar a su carpeta local (ejemplos: `"D:/Proyectos/Proyecto_Fase_2/datasets"` en Windows o `"/home/usuario/Proyecto_Fase_2/datasets"` en Linux/macOS).

2. **Carga e integraci√≥n**  
   - Se leen todos los `.xlsx`, se extrae el a√±o del nombre y se crean data frames `df_2018`‚Äì`df_2024`.
   - Se estandarizan nombres de columnas (min√∫sculas, sin acentos) y se homologa nomenclatura (`gran_grupos`, `subg_principales`, etc.).
   - Se descartan columnas inconsistentes (`edad_quinquenales`, `ocupacionhabitual`, `filter_$`) y se convierte `area_geo_inf` a num√©rico.  
   - Se consolidan los a√±os 2020‚Äì2024 en `df_final`, eliminando `num_corre`.

3. **√Årboles de decisi√≥n (`rpart`)**  
   - **Tipo de falta (`a_1`)**: predice `falta_inf` usando variables sociodemogr√°ficas y geogr√°ficas. Incluye ejemplos de predicci√≥n para perfiles sint√©ticos.  
   - **Grupo etario (`a_2`)**: clasifica en `edad_quinquenal` a partir de falta, a√±o, sexo, alfabetismo, √°rea, etc.  
   - **Escolaridad y a√±o de boleta**: √°rboles adicionales sobre `niv_escolaridad_inf` y `ano_boleta` (ver secciones posteriores del script).  
   - Cada √°rbol se grafica con `rpart.plot` y puede exportarse (`arbol_1.png`, `arbol_2.png`, etc.).

4. **Random Forest (`randomForest`)**  
   - Modelos de ensamble para **tipo de falta**, **sexo** y **√°rea geogr√°fica (urbano/rural)**.  
   - Par√°metros definidos en el script (p.ej., `ntree`, `mtry`) con `set.seed(42)` para reproducibilidad.  
   - Se generan m√©tricas de exactitud, matrices de confusi√≥n e importancia de variables (exportadas a `random_forest_*.png`).

5. **Ejecuci√≥n completa**  
   - Desde RStudio: *Source* (`Ctrl + Shift + Enter`).  
   - Desde terminal: `Rscript Fase_2.R`.

6. **Salidas esperadas**  
   - M√©tricas impresas en consola (accuracy, matriz de confusi√≥n).  
   - Gr√°ficos de √°rboles y bosques en PNG.  
   - Predicciones de prueba para perfiles sint√©ticos (en consola).

---

## ü§ñ Ejecuci√≥n en Python: Redes Neuronales Densas

1. **Activar entorno**  
   - Inicie el entorno virtual y aseg√∫rese de tener las dependencias instaladas (`pip install ...`).

2. **Abrir el notebook**  
   - `jupyter notebook redes_neuronales.ipynb` (o √°bralo en VS Code).  
   - Ajuste la variable `ruta` en la primera celda para que apunte a su carpeta `datasets` local.

3. **Carga y preparaci√≥n de datos**  
   - Se leen los mismos Excel usados en R, se unifican columnas y se codifican categor√≠as (limpieza con `unidecode`, `LabelEncoder`, `to_categorical`).
   - Se separan conjuntos de entrenamiento/prueba con `train_test_split` y se escalan variables num√©ricas con `StandardScaler`.

4. **Arquitecturas de red**  
   - **Red 1 (a√±o de la falta)**: capas `Dense` con activaci√≥n ReLU y salida softmax para predecir `ano_boleta`.  
   - **Red 2 (tipo de falta u objetivo indicado en el notebook)**: configuraci√≥n similar, con funci√≥n de p√©rdida y activaci√≥n acordes a si es binario o multiclase.  
   - Uso de `EarlyStopping` y optimizador `Adam`.  
   - Clase balanceada opcional con `compute_class_weight` seg√∫n la distribuci√≥n de etiquetas.

5. **Entrenamiento y evaluaci√≥n**  
   - Ejecute las celdas en orden. El notebook muestra el resumen del modelo, el proceso de entrenamiento y las m√©tricas (accuracy, matriz de confusi√≥n).  
   - Las gr√°ficas de curvas y matrices pueden guardarse como `red_neuronal_*.png`.

6. **Resultados**  
   - M√©tricas y tablas impresas en el notebook.  
   - Visualizaciones de desempe√±o (p√©rdida/accuracy por √©poca, matriz de confusi√≥n).  
   - Predicciones sobre perfiles sint√©ticos demostrativos.

---

## üß† Explicaci√≥n t√©cnica resumida

- **√Årboles de decisi√≥n (`rpart`)**: dividen el espacio de atributos maximizando la ganancia de informaci√≥n (medida con entrop√≠a). Cada nodo eval√∫a variables como `sexo_inf`, `edad_inf`, `area_geo_inf`, `gran_grupos`, etc.; las hojas asignan la clase mayoritaria. Las gr√°ficas `arbol_*.png` facilitan interpretar reglas y nodos terminales.

- **Random Forest**: ensamble de m√∫ltiples √°rboles entrenados sobre subconjuntos de variables/filas. Se controlan par√°metros como n√∫mero de √°rboles (`ntree`) y n√∫mero de variables por split (`mtry`). La importancia de variables se reporta en los gr√°ficos `random_forest_*.png`, √∫til para comparar qu√© atributos aportan m√°s a la predicci√≥n de falta, sexo o √°rea.

- **Redes neuronales densas (Keras)**: modelos `Sequential` con capas `Dense` y activaciones ReLU; la capa de salida usa softmax (multiclase) o sigmoid (binario). Se normalizan entradas y se aplican callbacks de parada temprana. Las m√©tricas principales son accuracy y matriz de confusi√≥n sobre el conjunto de prueba.

---

## üîÅ Reproducibilidad y buenas pr√°cticas
- El script en R fija semillas (`set.seed(42)`) antes de entrenar Random Forest; puede ajustarlas para replicar exactamente los resultados.
- En Python, defina semillas manualmente (`np.random.seed(...)`, `tf.random.set_seed(...)`) si necesita ejecuciones deterministas.
- Revise que no existan valores faltantes inesperados tras la limpieza y que las columnas categ√≥ricas queden correctamente codificadas.
- Si ejecuta en entornos sin interfaz gr√°fica, configure la salida de plots a archivos PNG en lugar de mostrarlos en pantalla.

---

## üë§ Autor
**Rodrigo Eduardo Hern√°ndez Morales**  
Maestr√≠a en Ciencia de la Computaci√≥n ‚Äì Especialidad en Ciencia de Datos  
Universidad de San Carlos de Guatemala
